## Fucntionality

- [ ] LLM
  - [ ] [Ollama](https://ollama.com/library/llama3.2:1b)
  - [ ] [GPU Acceleration]() and [docker](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)
- [ ] [Data Simluation](https://github.com/Swarm-Squad/Swarm-Squad-Ep2/blob/main/backend/scripts/run_simulation.py)
- [ ] Store llm_prompts from data sim
  - [ ] log files
  - [ ] tmp list - JSON
- [ ] continuouse message stream/exchange from sim script to LLM context window
  - [ ] [Send llm_prompts to llm](https://www.archgw.com/) or [this](https://github.com/katanemo/archgw)
    - [ ] every X messages
    - [ ] every X seconds
  - [ ] Acknowledge llm_prompts recieved
  - [ ] Based on prompts recieved, llm makes function calls


Example Projects / References

https://github.com/akshay56789/discord-weather-bot
